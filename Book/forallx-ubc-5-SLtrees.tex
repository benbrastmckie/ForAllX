%!TEX root = forallx-ubc.tex
\chapter{Sentential Tree Logic}
\label{ch.sl.trees}

So far we have focused on semantic means of evaluating SL argument forms for validity: an argument is valid just in case every interpretation that satisfies the premises also satisfies the conclusion.
We can check to see whether an argument is valid by constructing truth tables, representing all of the possible interpretations for the relevant sentence letters, and checking to see whether any of them do so.
This method has two main advantages: one is that it can be done in an entirely mechanical way--- it requires no particular rational insight or creativity, just straightforward applications of the characteristic truth tables.
Another benefit is that, assuming you apply the characteristic truth tables correctly, the procedure will always terminate, allowing you to identify whether the argument is valid or not.

The truth-table method also has a significant disadvantage: the method does not scale well with complexity.
In particular, it becomes extremely cumbersome for evaluating arguments with sentence letters.
For instance, to evaluate an argument like the one given below, you would need to consider a truth table with only four rows:

\begin{earg}
\item[] $P\eiff Q$
\item[] $\enot Q$
\item[] $\enot Q \eor (P \eif \enot Q)$
\item[\therefore] $\enot P \eif Q$
\end{earg}

But change just two of the atoms to new letters, and the required table will grow exponentially.
For this argument, you'd need sixteen rows.

\begin{earg}
\item[] $P\eiff Q$
\item[] $\enot A$
\item[] $\enot Q \eor (A \eif \enot B)$
\item[\therefore] $\enot P \eif B$
\end{earg}

For this one, you'd need two hundred fifty-six!

\label{8letterargument}
\begin{earg}
\item[] $A\eiff B$
\item[] $\enot B \eif (C \eor D)$
\item[] $E \eif \enot C$
\item[] $(\enot D \eand F) \eor G$
\item[] $\enot A \eand E$
\item[\therefore] $H \eor G$
\end{earg}

So it is useful to have alternate ways of proving entailments.
Another method that we have sketched is to make direct use of the semantic clauses rather than the characteristic truth tables for each logical connective.
For instance, in order to evaluate the validity of any of the arguments above, we may consider an arbitrary interpretation $\I$ which satisfies the premises.
By using the semantic clauses to work out the results, we may check to see whether the conclusion is also satisfied.
Although this avoids having to construct large truth tables, it can be cumbersome to present these arguments.
Moreover, such arguments end up making the same moves again and again, suggesting that there may be a way to further economize.

For instance, consider the argument:

\begin{earg}
  \item[] $A \eand B$
  \item[] $A \eif C$
  \item[\therefore] $C$
\end{earg}

Suppose that $\I$ is an interpretation that satisfies the premises, and so $\V{\I}(A \eand B)=1$ and $\V{\I}(A \supset C)=1$.\footnote{If this assumption leads to a contradiction, we may conclude that there is no such interpretation, and so conclude that the argument is vacuously valid. As we will see, the validity of this argument is non-vacuous.}
By the semantic clause for conjunction, it follows that $\V{\I}(A)=1$ and $\V{\I}(B)=1$.
Similarly, by the semantic clause for the material conditional, either $\V{\I}(A)=0$ or $\V{\I}(C)=1$.
Since we know that $\V{\I}(A)\neq 0$, it follows that $\V{\I}(C)=1$.
Given that $\I$ was an \textit{arbitrary} interpretation that satisfies the premises, we may conclude more generally that \textit{any} interpretation that satisfies the premises also satisfies the conclusion.

Consider the inference from $\V{\I}(A \eand B)=1$ to $\V{\I}(A)=1$, using the semantics for conjunction. 
Although we could continue to evaluate the validity of arguments by using such inferences, there is sure to be lots of repetition where even if the sentences themselves differ, the basic form of reasoning is preserved.
Accordingly, it is natural to ask how we might begin to schematize such patterns of reasoning, making it easier to argue from the truth of the premises to the truth of the conclusion on an arbitrary interpretation.

In this chapter we will rise to this challenge by introducing a \emph{proof system} for SL.
The proofs we will construct in this chapter are called \define{analytic tableaux}.
Another name for them is \define{trees}, because of the way they branch (the trees will be upside down, or you can think of the roots of a tree).
In Ch.\ \ref{ch.ND.proofs} we will examine a natural deduction proof system.





\section{Unsatisfiability and Entailment}

The method of trees is most directly a way to test for satisfiability of a set of SL sentences.
Since the validity of an argument is definable in terms of entailment, and entailment is definable in terms of satisfiability, this method also provides a way to test for the validity of SL arguments.
In order to make these connections precise, consider the following principle:

\factoidbox{
  In general, $\Gamma \models \metaA$ if and only if $\Gamma, \enot \metaA \models \bot$.
}

The principle above holds for any set of SL sentences $\Gamma$ and any SL sentence $\metaA$. 
It is worth noting that `$\Gamma, \enot \metaA$' has been used in place of `$\Gamma \cup \set{\enot \metaA}$', where this abbreviation is in keeping with our practice of dropping set notation for ease of exposition.
To establish this principle, we need only look to the definitions given in the previous chapter.

Recall the definition of entailment from \S\ref{sec:entailment}: $\Gamma \models \metaA{}$ just in case every interpretation that satisfies $\Gamma$ also satisfies $\metaA{}$. 
Assuming $\Gamma \models \metaA{}$, it follows that any interpretation to satisfy $\Gamma$ does not satisfy $\enot \metaA$.
Thus there is no interpretation that satisfies $\Gamma \cup \set{\enot \metaA{}}$, and so vacuously, every interpretation to satisfy $\Gamma \cup \set{\enot \metaA{}}$ also satisfies $\bot$.
By the definition of entailment, $\Gamma, \enot \metaA{} \models \bot$, thereby establishing the left-to-right (\textsc{ltr}) direction: if $\Gamma \models \metaA{}$, then $\Gamma, \enot \metaA{} \models \bot$.
The converse direction proceeds along similar lines.

Given the principle above, if you want to tell whether an argument in SL is valid, all we need to do is check whether the set of premises along with the negation of the conclusion is satisfiable.
If so, the argument is invalid.
If they're not, the argument is valid.
This is the basic idea behind the tree method of proof.
We'll write down the sentences we're attempting to satisfy, and then we'll work through their consequences, in order to see whether it's possible to complete the task.
Let's begin by working through an example that illustrates the general idea, then come back to give precise rules.




\section{Proving Validity}

Let's evaluate whether the following argument is valid in SL:

\begin{earg}
\item[] $A\eand B$
\item[] $\enot(C\eor D)$
\item[] $(\enot B \eor C) \eor E$
\item[\therefore] $E$
\end{earg}

We know that the argument is valid just in case its premises entail its conclusion.
Given the principle brought out in the previous section, we may conclude that the argument is valid just in case the premises together with the negation of the conclusion is unsatisfiable.
Thus, we may begin by writing down the sentences we're going to attempt to satisfy, i.e., the premises as they are above together with the negation of the conclusion:

\begin{prooftree}
{ % begin tree preamble
single branches,
close with=\ensuremath{\times},
%to prove={\{A\eand B, \enot(C\eor D), (\enot B\eor C)\eor E\} \vdash{} E}
} % end tree preamble
[A\eand B
[\enot(C\eor D), grouped
[(\enot B \eor C) \eor E, grouped
[\enot E, grouped, name=negconc
%	[A
%	[B, grouped
%		[\enot C
%		[\enot D, grouped
%			[\enot B \eor C
%				[\enot B, close]
%				[C, close]
%			]
%			[E, close]					
%		]
%		]
%	]
%	]
]
]
]
]
\end{prooftree}

Notice that we're putting the \emph{negation} of the conclusion here in line (4).
The sentences we write down at the beginning of the tree, we call the \define{root}.
Trees are designed to show whether the root is satisfiable, and if so, how to satisfy it.

With proof trees, the idea is to continue writing down that which our previous lines \emph{already commit us to}, or put otherwise, what \textit{follows logically} from our previous commitments.
Consider the first line, $A \eand B$.
For this conjunction to be true, both conjuncts must be true.
So any interpretation that satisfies the top four lines must also satisfy both $A$ and $B$; the truth of those sentences is a commitment of what we already have. Each follow from what is already written down. We represent this by continuing the tree with those sentences:


\begin{prooftree}
{ % begin tree preamble
single branches,
close with=\ensuremath{\times},
%to prove={\{A\eand B, \enot(C\eor D), (\enot B\eor C)\eor E\} \vdash{} E}
} % end tree preamble
[A\eand B, checked
[\enot(C\eor D), grouped
[(\enot B \eor C) \eor E, grouped
[\enot E, grouped
	[A
	[B, grouped
%		[\enot C
%		[\enot D, grouped
%			[\enot B \eor C
%				[\enot B, close]
%				[C, close]
%			]
%			[E, close]					
%		]
%		]
	]
	]
]
]
]
]
\end{prooftree}

In addition to introducing lines (5) and (6), we also add a check mark on (1), to indicate that we've now considered it and represented its consequences. Think of the check mark as saying that we've extended the tree in a way that encodes the information from this line.

Now consider line (2). This is a negated disjunction. Disjunctions are true any time either disjunct is true, so this \emph{negated} disjunction can only be true if \emph{both} disjuncts are \emph{false}. So we include new lines for \enot $C$ and \enot $D$, adding a check mark on line (2):

\begin{prooftree}
{ % begin tree preamble
single branches,
close with=\ensuremath{\times},
%to prove={\{A\eand B, \enot(C\eor D), (\enot B\eor C)\eor E\} \vdash{} E}
} % end tree preamble
[A\eand B, checked
[\enot(C\eor D), grouped, checked
[(\enot B \eor C) \eor E, grouped
[\enot E, grouped
	[A
	[B, grouped
		[\enot C
		[\enot D, grouped
%			[\enot B \eor C
%				[\enot B, close]
%				[C, close]
%			]
%			[E, close]					
		]
		]
	]
	]
]
]
]
]
\end{prooftree}

Line (3) is a disjunction. Unlike the previous two cases, it doesn't tell us what is determinately the case, but rather that at least one of the disjuncts is true.
We represent this in our tree by \emph{branching} into two different columns:

\begin{prooftree}
{ % begin tree preamble
single branches,
close with=\ensuremath{\times},
%to prove={\{A\eand B, \enot(C\eor D), (\enot B\eor C)\eor E\} \vdash{} E}
} % end tree preamble
[A\eand B, checked
[\enot(C\eor D), grouped, checked
[(\enot B \eor C) \eor E, grouped, checked
[\enot E, grouped
	[A
	[B, grouped
		[\enot C
		[\enot D, grouped
			[\enot B \eor C
%				[\enot B, close]
%				[C, close]
			]
			[E, close]					
		]
		]
	]
	]
]
]
]
]
\end{prooftree}

Think of these two branches as representing the idea that the root implies that at least one of the disjuncts is true.
Accordingly, we have two branches to consider.
Start by examining the branch of the right: it gives an atomic sentence, $E$.
Notice, however, that line (4) was \enot $E$.
So if we're looking for a way to satisfy (1)-(4), this right branch isn't going to work since it requires $E$ to be true, and it also requires \enot $E$ to be true.
If a branch contains any sentence as well as its negation, we know that there is no interpretation to satisfy all sentences on that branch.
Thus we may say that the branch is \emph{closed}, marking it with an `\ensuremath\times'.

The left branch corresponds to a different interpretation, and must be considered separately.
Here we have another disjunction.
It too branches out into two more disjuncts:

\begin{prooftree}
{ % begin tree preamble
single branches,
close with=\ensuremath{\times},
%to prove={\{A\eand B, \enot(C\eor D), (\enot B\eor C)\eor E\} \vdash{} E}
} % end tree preamble
[A\eand B, checked
[\enot(C\eor D), grouped, checked
[(\enot B \eor C) \eor E, grouped, checked
[\enot E, grouped
	[A
	[B, grouped
		[\enot C
		[\enot D, grouped
			[\enot B \eor C, checked
				[\enot B, close]
				[C, close]
			]
			[E, close]					
		]
		]
	]
	]
]
]
]
]
\end{prooftree}

Observe that both of these new disjuncts result in closed branches.
The left branch at (10) is the negation of (6), and the right branch is the negation of (7).
Now every branch in this tree is closed.
This corresponds to the idea that every possible way there could be to satisfy (1)-(4) ended up requiring a contradiction.
There is no interpretation that satisfies (1)-(4).
In other words, the set of premises together with the negation of the conclusion is unsatisfiable, and so the premises entail the conclusion.
Thus the argument we began with is valid.

In the previous chapter we used the double turnstile, `$\models$', to represent entailment.
In this chapter we will use a different but related symbol, the \define{single turnstile}, which looks like this: $\vdash$.
Think of this symbol as representing \emph{provability}, or put otherwise, what conclusions are \textit{derivable} from which sets of premises.
So in proving that $E$ follows from the premises above, we're showing that {\{$A\eand B$, \enot$(C\eor D)$, $(\enot B\eor C)\eor E\} \vdash{} E$}.
As before, it is convenient to drop the set notation: $A\eand B,\ \enot(C\eor D),\ (\enot B\eor C)\eor E\ \vdash E$.

As we will later show, provability and entailment will turn out to have the same extension, allowing us to move from claims about entailment to claims about provability and \textit{vice versa}.
We'll consider these result in detail in Chapter \ref{ch.SLsoundcomplete}.
For the time being, lets work through another example, demonstrating how the proof system accommodates invalid arguments.





\section{Proving Invalidity}
\label{sec.SLinvalidtree}

In \S\ref{sec.SLtreerules} we'll learn the formal rules for trees in SL.
For now, we will continue to introduce trees by example, giving you a sense of the moves that we can make with this system.
In particular, it is important to consider what happens if we are to evaluate an invalid argument:

\begin{earg}
\item[] $(D\eor A) \eand \enot N$
\item[] $N \eor \enot A$
\item[\therefore] $\enot N \eand A$
\end{earg}

As before, we'll construct a tree that includes the premises and the negation of the conclusion at the top, and we'll attempt to find an interpretation satisfying those three lines.
By convention, we write the claim we're attempting to prove at the top of the tree. 

\begin{prooftree}
{
to prove={(D\eor A) \eand \enot N,\ N \eor \enot A \vdash \enot N \eand A},
single branches,
close with=\ensuremath{\times},
}
[(D\eor A) \eand \enot N,
[N \eor \enot A, grouped,
[\enot (\enot N \eand A), grouped%, checked
% 	[D \eor A%, checked
% 	[\enot N, grouped
% 		[N, close
% 		]
% 		[\enot A
% %			[\enot\enot N, close
% %			]
% %			[\enot A
% %				[D]
% %				[A, close]
% %			]
% 		]
% 	]
% 	]
]
]
]
\end{prooftree}

We begin by processing line (1), which is a conjunction; its conjuncts are given in (4) and (5).
Line (6) processes the disjunction in line (2), and the left branch closes.

\begin{prooftree}
{
to prove={(D\eor A) \eand \enot N,\ N \eor \enot A \vdash \enot N \eand A},
single branches,
close with=\ensuremath{\times},
}
[(D\eor A) \eand \enot N, checked
[N \eor \enot A, grouped, checked
[\enot (\enot N \eand A), grouped%, checked
	[D \eor A%, checked
	[\enot N, grouped
		[N, close
		]
		[\enot A
%			[\enot\enot N, close
%			]
%			[\enot A
%				[D]
%				[A, close]
%			]
		]
	]
	]
]
]
]
\end{prooftree}

Whereas the left branch at (6) closes because it's the negation of line (5), the right branch at (6) remains open.
We may then move on to consider line (3) which is a negated conjunction.
Since a conjunction is true if and only if both conjuncts are true, a conjunction is false if at least one conjunct is false.
Thus in order to resolve (3), line (7) branches from all remaining open branches into the negation of each conjunct, \enot\enot$N$ and \enot$A$.

\begin{prooftree}
{
to prove={\{(D\eor A) \eand \enot N, N \eor \enot A\} \vdash{} \enot N \eand A},
single branches,
close with=\ensuremath{\times},
}
[(D\eor A) \eand \enot N, checked
[N \eor \enot A, grouped, checked
[\enot (\enot N \eand A), grouped, checked
	[D \eor A, 
	[\enot N, grouped
		[N, close
		]
		[\enot A
			[\enot \enot N, close
			]
			[\enot A
				% [D, open]
				% [A, close]
			]
		]
	]
	]
]
]
]
\end{prooftree}

Since the left branch at (7) is the negation of (5), the left branch closes.
The final sentence that requires resolution is the disjunction on line (4) which produces two more branches.

\begin{prooftree}
{
to prove={\{(D\eor A) \eand \enot N, N \eor \enot A\} \vdash{} \enot N \eand A},
single branches,
close with=\ensuremath{\times},
}
[(D\eor A) \eand \enot N, checked
[N \eor \enot A, grouped, checked
[\enot (\enot N \eand A), grouped, checked
	[D \eor A, checked
	[\enot N, grouped
		[N, close
		]
		[\enot A
			[\enot \enot N, close
			]
			[\enot A
				[D, open]
				[A, close]
			]
		]
	]
	]
]
]
]
\end{prooftree}

Since the right branch at (8) contradicts (7), the right branch closes.
However, something similar cannot be said for the left branch at (8) which remains open.
The `$\uparrow$' indicates that the open branch ending in $D$ is a \emph{completed} branch. 

We'll precisely define `completion' in \S\ref{sec.SL.tree.completion}, but intuitively what this means is that this branch represents a way to satisfy all three sentences at the root of the tree.
In other words, this argument form is \emph{not} valid in SL.
Furthermore, examining the open branch demonstrates an interpretation that satisfies the root.
Letting a \textit{literal} be any sentence letters or the negation of any sentence letter, the completed branch includes three literals: \enot $A$, $D$, and \enot $N$.
Accordingly, the completed branch suggests the following interpretation:

\begin{displaymath}
	\begin{array}{ll}
    \I(A) = 0\\
    \I(D) = 1\\
    \I(N) = 0
	\end{array}
\end{displaymath}

You can verify this result by evaluating the premises and the conclusion of the argument we began with on this interpretation. Since there is an interpretation that satisfies the premises and falsifies the conclusion, our tree system proves the argument invalid.





\section{Closure Rules}

Hopefully the examples above give you some sense of the tree method for SL.
Nevertheless, we have not yet defined what counts as proof by giving formal rules. 
We will attend to these details in the following subsections, beginning with \define{closure} rules.
It is important to be clear that a \define{branch} is a continuous linear pathway which starts at the root of a tree and continues down to the bottom of the tree (to a \define{leaf}) without ever turning back on itself.

In the tree examples above, we \emph{closed} branches when they contained sentences along with their negations. Here is our general rule for tree closure:

\factoidbox{
If a branch contains both \metaA{} and \enot\metaA{}, that branch is \define{closed}.
We mark closed branches with the `\ensuremath{\times}' symbol.
Any branch that is not closed is \define{open}.
\vspace{.05in}

A tree is \define{closed} if and only if every branch in that tree is closed.
A tree is \define{open} if and only if it is not closed.
}

If every branch is closed, the method proves that the root is unsatisfiable.

Note that `\metaA{}' stands in for \emph{any} sentence of SL; it is not part of the closure rule that one must have an atomic sentence and its negation. Consider for example this tree:

\begin{prooftree}
{
}
[(\enot\enot S \eand T) \eif (\enot P \eiff (Q \eor R)), checked
[\enot\enot S \eand T, grouped, name={p2}
[\enot (\enot P \eiff (Q\eor R)), grouped, name={p3}
	[\enot(\enot\enot S \eand T), close={:p2,!c}
	]
	[(\enot P \eiff (Q \eor R)), close={:p3,!c}
	]
]
]
]
\end{prooftree}

In this tree, we only resolved the first sentence, using the conditional rule, and the tree immediately closed.
The line numbers under the closure symbols specify exactly why the branches close: the left branch developed into the negation of (2), and the right branch developed into the negation of (3).
Notice that we \emph{could} have developed lines (2) and (3), using the conjunction or negated biconditional rules, respectively, but this would have resulted in a more complicated tree that ultimately yielded the same result.
Similarly, if we hadn't noticed that both branches close at line (4), we could have continued processing the tree, developing the left branch using the negated conjunction rule on (4), and developing the right branch using the biconditionals rule.
But this too would have involved needless complication for no benefit.
You can save yourself a lot of work by noticing when branches are ready to mark as closed, and by thinking a bit strategically about which sentences to resolve first.





\section{Resolution Rules for SL Trees}
\label{sec.SLtreerules}

We now turn to the \define{resolution} rules which provide ways that tree branches can be extended given the sentences that are already in that branch.
These rules will depend on the main connective of the sentence in question, where if the main connective is negation, then they will also depend on the main connective of the negand.




\label{SL.treerules.start}
\subsection{Conjunction}

If you have a conjunction on an open branch, you may make a linear extension of that branch to include each conjunct.
Here is the conjunction rule.

\factoidbox{
\begin{center}
\begin{prooftree}
{not line numbering}
[\metaA{}\eand\metaB{}
	[\metaA{}
	[\metaB{}, grouped
	]
	]
]
\end{prooftree}
\end{center}
}




\subsection{Negated conjunction}

If you have a negated conjunction on an open branch, you may resolve it by branching into the negation of each conjunct.
This makes sense because there are two ways for a negated conjunction to be true: either conjunct can be false.

\factoidbox{
\begin{center}
\begin{prooftree}
{not line numbering,
single branches}
[\enot(\metaA{}\eand\metaB{})
	[\enot\metaA{}]
	[\enot\metaB{}]
]
\end{prooftree}
\end{center}
}




\subsection{Disjunction}
\label{subsec.DisjunctionTreeRule}
\begin{groupitems}

If you have a disjunction on an open branch, you may resolve the disjunction by creating a branch for each disjunct.

\factoidbox{
\begin{center}
\begin{prooftree}
{not line numbering,
single branches}
[\metaA{}\eor\metaB{}
	[\metaA{}]
	[\metaB{}]
]
\end{prooftree}
\end{center}
}
\end{groupitems}





\subsection{Negated disjunction}

Since disjunctions are true any time either disjunct is true, they are only false if both disjuncts are false.
So negated disjunctions on an open branch are resolved with a linear development containing the negation of each disjunct.

\factoidbox{
\begin{center}
\begin{prooftree}
{not line numbering,
single branches}
[\enot(\metaA{}\eor\metaB{})
	[\enot\metaA{}
	[\enot\metaB{}, grouped
	]
	]
]
\end{prooftree}
\end{center}
}

\subsection{Conditional}

Recall the semantic clause for the conditional:
$$\V{\I}(\metaA \eif \metaB)=1 ~\text{just in case}~ \V{\I}(\enot \metaA)=1 ~\text{or}~ \V{\I}(\metaB)=1.$$ 
Conditionals are true any time the antecedent is false or the consequent is true.
Thus a conditional on an open branch is resolved by creating a branch with the negation of the antecedent as well as a branch with the consequent.

\factoidbox{
\begin{center}
\begin{prooftree}
{not line numbering,
single branches}
[\metaA{}\eif\metaB{}
	[\enot\metaA{}]
	[\metaB{}]
]
\end{prooftree}
\end{center}
}

\subsection{Negated conditional}

As in the case of negated disjunctions, the negation of a conditional is a relatively strong claim: the only way for a conditional to be false is for its antecedent to be true \emph{and} for its consequent to be false.
Thus if a negated conditional is on an open branch, we may append the antecedent followed by the negation of the consequent.

\factoidbox{
\begin{center}
\begin{prooftree}
{not line numbering,
single branches}
[\enot(\metaA{}\eif\metaB{})
	[\metaA{}
	[\enot\metaB{}, grouped
	]
	]
]
\end{prooftree}
\end{center}
}

\subsection{Biconditional}

Biconditionals require a slightly different structure than the rules that we have already considered.
A biconditional says that two sentences have the same truth value: either both are true, or both are false.
Since these represent two different ways a biconditional can be true, biconditionals that occur on open branches will be resolved with two new branches.
However, unlike the other branching rules, each new branch will contain two sentences.

\factoidbox{
\begin{center}
\begin{prooftree}
{not line numbering,
single branches}
[\metaA{}\eiff\metaB{}
	[\metaA{}
		[\metaB{}, grouped]
	]
	[\enot\metaA{}
		[\enot\metaB{}, grouped]
	]
]
\end{prooftree}
\end{center}
}

Whereas the branch on the left represents the truth of both sides of the biconditional, the branch on the right represents the falsity of both sides of the biconditional.





\subsection{Negated biconditional}
\begin{groupitems}

Negated biconditionals on open branches induce two new branches in a similar fashion to non-negated biconditionals, but this time a negation sign is appended to only one of the subsentences inside the scope of the negation.
The two branches capture the two different ways that this can be done.

\factoidbox{
\begin{center}
\begin{prooftree}
{not line numbering,
single branches}
[\enot(\metaA{}\eiff\metaB{})
	[\metaA{}
		[\enot\metaB{}, grouped]
	]
	[\enot\metaA{}
		[\metaB{}, grouped]
	]
]
\end{prooftree}
\end{center}
}
\end{groupitems}





\subsection{Double negation}

There is one more resolution rule, for double-negated sentences.
A double negation on an open branch may be resolved by appending the negand of the negand, i.e., the sentence obtained by removing two negations from the left of the double-negation in question.

\factoidbox{
\begin{center}
\begin{prooftree}
{not line numbering, single branches}
[\enot\enot\metaA{}
	[\metaA{}]
]
\end{prooftree}
\end{center}
}
\label{SL.treerules.end}




\subsection{Resolution}

These nine resolution rules specify precisely how to resolve most sentences of SL.
The only exceptions are the literals, i.e., the sentence letters and their negations.
In our proof system, literals play a special role: they are not resolved, but rather encode in a purely syntactic way the truth or falsity of the interpretation corresponding to each branch.
In developing a tree proof, you may apply any of these rules to any sentence besides the literals in any branch in which that sentence occurs.
Once you have extended all open branches in which a given (non-literal) sentence occurs by applying the appropriate resolution rule, the sentence in question is \define{resolved}.
Mark resolved sentences with a check.

Note that it is \emph{not} a rule that sentences must be resolved in the order in which they appear in the tree.
Rather, it is often strategic to save sentences and come back to resolve them later.
For instance, if you are resolving a sentence after the tree has already done some branching, then you must perform the resolution rule under \emph{each} open branch that includes that sentence.
So in general, it is a good idea to branch only when there are no linear (non-branching) rules left to apply.
Here is a tree illustrating the issue.

\begin{prooftree}
{
}
[(D \eand \enot R) \eor Q, name={p1}, checked
[\enot Q \eor R, grouped, checked, name={p2}
	[D \eand \enot R, just={\eor}:p1, name={and}, checked
		[\enot Q, just={\eor}:p2
			[D, just={\eand}:and
				[\enot R, grouped, open]
			]
		]
		[R, name={R}
			[D, just={\eand}:and
				[\enot R, grouped, close={:R,!c}]
			]
		]
	]
	[Q
		[\enot Q, close={:!u,!c}
		]
		[R, open
		]
	]
]
]
\end{prooftree}

This tree has two disjunctions in the root, so it will involve branching multiple times.
We could start with either one, but this tree resolved line (1) first, branching into the two disjuncts at line (3).
The `1 \eor' to the right at that line explains what is happening there: it indicates that the disjunction rule was applied to line (1).
Officially, these notes on the side are auxiliary to the proof itself, but can help keep track of what is going on.
When the second disjunction is processed at line (4), it needs to be done on both branches, since both branches include line (2).
That's why our two branches split into four at line (4).
One branch closes at that point.
At line (5), the conjunction at line (3) is processed.
This needs to be done on both branches that include that conjunction, but not the right-most branch, which does not include it.
More generally, resolving a sentence affects every branch in which it occurs, but does not effect the other branches.






\section{Completion Rules}
\label{sec.SL.tree.completion}

In our examples above we have used `$\uparrow$' to indicate that an open branch is complete.
We now need a precise characterization of branch completion.

In SL, a \define{resolvable} sentence is any sentence for which we have a resolution rule, that is, any sentence besides the literals.
We may then specify the following:

\factoidbox{
  A branch is \define{complete} if and only if every resolvable sentence in that branch has been resolved.
  A tree is \define{complete} if and only if every branch is complete.
}

Since the resolution rules are only applied on open branches, the resolution rules are vacuously satisfied on closed branches, and so every resolvable sentence on a closed branch is resolved.
Accordingly, closed branches are complete.
However, the converse is not true: a branch may be complete because all of the resolvable sentences have been resolved, and yet the branch remains open.
We may mark complete branches that remain open with `$\uparrow$' as above.

If there is at least one open branch in a completed tree, that branch corresponds to an interpretation which satisfies the set of sentences which occur in the root.
By contrast, if every branch in a tree is closed, there is no corresponding interpretation which satisfies the root.
Given any set of SL sentences $\Gamma$, we may write $\Gamma \vdash \bot$ just in case there is a closed tree whose root consists of all and only the sentences in $\Gamma$.
Similarly, we use `$\Gamma \nvdash \bot$' to indicate that there is a complete and yet open tree whose root consists of all and only the sentences in $\Gamma$.
By contrast with `$\models$' which expresses the semantic notion of entailment, the `$\vdash$' symbol is purely syntactic, specifying the existence of an appropriate SL tree.

We may take `$\vdash$' to express \textit{derivational validity}, or more simply, we may take `$\Gamma \vdash \metaA$' to express that $\metaA$ is \define{derivable} from $\Gamma$. 
In particular, if $\Gamma \vdash \bot$, we may say that the canonical contradiction $\bot$ is derivable from $\Gamma$.
This makes sense given that $\Gamma \vdash \bot$ just in case there is a tree whose root sentences make up $\Gamma$ that is closed, i.e., every branch contains a contradictory pair $\metaA$ and $\enot \metaA$ for some SL sentence $\metaA$. 

Given the derivation relation $\vdash$, we may stipulate that $\Gamma \vdash \metaA$ just in case $\Gamma \cup \set{\enot \metaA} \vdash \bot$, or leaving off set notation, $\Gamma, \enot\metaA\ \vdash \bot$.
Intuitively, `$\Gamma \vdash \metaA$' expresses that $\metaA$ is derivable from $\Gamma$ since a contradictory pair of sentences is guaranteed to follow from $\Gamma$ together with $\enot \metaA$.
This closely resembles an argument form commonly referred to as \textit{reductio ad absurdum} where, given some premises $\Gamma$, one seeks to establish a conclusion $\metaA$ by assuming $\enot \metaA$ and reasoning to a contradiction. 
SL tree proofs may be interpreted as instituting this method as a general procedure by which to evaluate arguments in SL.

It is important to emphasise that what is being evaluated is not validity, or entailment, or anything semantic.
Rather, SL tree proofs and the corresponding notion of derivation is no more than a systematic means of manipulating uninterpreted symbols.
However, as we will show in Ch.~\ref{ch.SLsoundcomplete}, SL trees have been carefully defined so that $\vdash$ and $\models$ have the same extension: $\Gamma \vdash \metaA$ if and only if $\Gamma \models \metaA$.
Not only does this result give us a good reason to use SL trees given that we already care about entailment as a means to evaluate the validity of arguments, this result will help to explain why the tree method works at all.

This completes the introduction to the SL tree proof system.
In the remaining sections, we will work through some more examples and provide advice for efficiently constructing trees.
% In Ch.~\ref{ch.ND.proofs}, we will consider another proof system for SL which more closely resembles the natural patterns by which humans reason.



\section{Resolution order}

The resolution rules do not specify the order in which you should resolve sentences in a tree; you are free to resolve in any order you like.
But some ways of processing trees are more efficient than others.
Here is an example to illustrate.
Suppose we want to consider whether $\enot (C \eand A),\ D \eiff C,\ A \eor B,\ \enot B\ \vdash{}\bot$.
So we put those sentences in the root of a tree.
Here's what happens if we resolve the sentences in the order in which they're given:

\begin{prooftree}
{
}
[\enot (C \eand A), checked, name=p1
[D \eiff C, checked, grouped, name=p2
[A \eor B, grouped, checked, name=p3
[\enot B, grouped, name=p4
	[\enot C, just={\enot\eand}:p1
		[D, just={\eiff}:p2
			[C, grouped, close]
		]
		[\enot D
			[\enot C, grouped
				[A, just={\eor}:p3, open]
				[B, close]
			]
		]
	]
	[\enot A
		[D
			[C, grouped
				[A, close]
				[B, close]
			]
		]
		[\enot D
			[\enot C, grouped
				[A, close]
				[B, close]
			]
		]
	]
]
]
]
]
\end{prooftree}

The justifications for particular steps are added on the right for clarity.
For example, `1 \enot\eand{}' indicates that line (5) was produced by performing the negated conjunction resolution rule on line (1).
This tree remains open, offering this interpretation that satisfies the root:

\begin{displaymath}
\script{I} =
\left\{
	\begin{array}{ll}
	A = 1\\
	B = 0\\
	C = 0\\
	D = 0
	\end{array}
\right.
\end{displaymath}

This tree reminds us again that if a sentence in a tree has multiple open branches below it, then resolving that sentence requires that the resolution be performed in \emph{each} open branch below.
That's why, for example, resolving line (3) at line (8) requires three different new branchings.
We do not resolve under the left-most column, because it is already closed.
So when there are more open branches, resolving sentences requires more work on the tree.
Consequently, it is sometimes a good idea to think a bit strategically, and close off parts of the tree earlier, to save yourself some work.

The example above is a perfectly fine instance of a completed tree, and it does yield the correct answer.
However, it's possible to get there with less work, by choosing to resolve sentences that will close off branches right away.
Here is another way of developing a tree with the same root as in the previous example.
This version begins by resolving line (3), because doing so will close off one of its new branches immediately.
It then continues to resolve in the most efficient order:

\begin{prooftree}
{
}
[\enot (C \eand A), checked, name=p1
[D \eiff C, checked, grouped, name=p2
[A \eor B, grouped, checked, name=p3
[\enot B, grouped, name=p4
	[A, just={\eor:p3}
		[\enot C, just={\enot\eand:p1}
			[D, just={\eiff:p2}
				[C, grouped, close]]
			[\enot D
				[\enot C, grouped, open]]
		]
		[\enot A, close]
	]
	[B, close]
]
]
]
]
\end{prooftree}

This tree gets us to the same result much more quickly, pointing to the same interpretation that satisfies the root.
As a general rule of thumb, it's good advice to look a step ahead, and resolve sentences that won't lead to new open branches, before resolving ones that will.
For just the same reason, it is usually more efficient to resolve those sentences that have linear rules before those that have branching rules.

\section{Choosing the Right Root}
\label{sec.sl.treeroots}

Trees are used to indicate whether the root is satisfiable by purely syntactic means.\footnote{Proving this is the aim of the next chapter.}
We test arguments for validity with a tree by putting their premises along with the negation of their conclusions in the root.
If the tree remains open, then the set is satisfiable, and so it is possible to satisfy the premises while falsifying the conclusion.
Thus the argument is invalid.
If the tree closes, the argument is valid.

But trees can be used to evaluate many other kinds of questions, aside from validity.
Any question that can be converted into a question about satisfiability can be answered with a tree.
For example, if you want to find out whether a set of sentences is consistent, put that set of sentences into the tree.
A set of sentences is consistent if and only if there is an interpretation satisfying it, so you can use a tree to find out.

What if you want to find out whether a sentence is a tautology? 
Since tautologies are satisfied by every interpretation, we may test this claim by attempting to find an interpretation that satisfies its negation, taking the negation to be the root.
If the completed tree remains open, it shows us how to satisfy the negation of the sentence in question, and so the sentence being negated is \emph{not} a tautology.
However, if the tree closes, then the negation is unsatisfiable, which means the sentence negated \emph{is} a tautology.

Similarly, see if a sentence is a contradiction, check if it is possible to satisfy it by making it the root of a tree.
If the completed tree remains open, the sentence is satisfiable, which means it's not a contradiction.
If the tree closes, then it is a contradiction.

To use a tree to answer a question, the first step is always to convert the question into a question about whether some sentence, or set of sentences, is satisfiable. 

\vspace{-2em}


\iffalse

\practiceproblems

\vspace{-2em}

If you want additional practice, you can construct trees for any of the SL arguments and entailment claims in the exercises for the previous two chapters.

\solutions
\problempart 
\label{pr.sl.treeroot}
To evaluate each of the following claims with a tree, (a) what would you put in the root of the tree?, and (b) if the tree closes, does that show that the claim is true or false?
\begin{earg}
\item $\{P, P \eif Q, Q \eif \enot P\} \vdash{}\bot$
%(a) $\{P, P \eif Q, Q \eif \enot P\}$, (b) true
\item $(P \eif Q) \eiff (Q \eif P)$ is a tautology.
%(a) $\enot((P \eif Q) \eiff (Q \eif P))$, (b) true
\item The following argument is valid:
	\begin{ekey}
		\item[] $P \eand Q$
		\item[] $\enot R \eif \enot Q$
		\item[\therefore] $P \eand R$
	\end{ekey}
%(a) $\{P \eand Q, \enot R \eif \enot Q, \enot (P \eand R)\}$, (b) true
\item There is no interpretation that satisfies $A \eor B$, $B \eif C$, and $A \eiff C$ without also satisfying C.
%$\{A \eor B, B \eif C, A \eiff C, \enot C\}, (b) true
\item $A \eiff \enot A$ is a contradiction.
%(a) $A \eiff \enot A$, (b) false
\item Every interpretation satisfying $P$, $P \eif Q$, and $\enot Q$ also satisfies $A$.
%(a) $\{P, P \eif Q, \enot Q, \enot A\}$
\item There is at least one interpretation that satisfies $P \eif Q$, $\enot P \eor \enot Q$, and $Q \eif P$.
%(a) $\{P \eif Q, \enot P \eor \enot Q, Q \eif P\}, (b) false.
 \end{earg}

\solutions
\problempart 
\label{pr.sl.agtree}
Evaluate the argument given on p.\ \pageref{8letterargument} by constructing a tree. If it is invalid, give a model demonstrating it so.

\solutions
\problempart Evaluate each claim from Part \ref{pr.sl.treeroot} by constructing a tree. If applicable, give the interpretation that demonstrates the claim true or false.
\label{tree.examples}

\problempart Recall the discussion of the Sheffer stroke in Chapter \ref{ch.TruthTables}, page \pageref{pr.altConnectives}.  That connective, if added to SL, would have this characteristic truth table:

\begin{center}
\begin{tabular}{c|c|c}
\metaA{} & \metaB{} & \metaA{}$|$\metaB{}\\
\hline
1 & 1 & 0\\
1 & 0 & 1\\
0 & 1 & 1\\
0 & 0 & 1
\end{tabular}
\end{center}

What would be appropriate resolution rules for the Sheffer stroke, or the negated Sheffer stroke?

\fi 
